{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>NUMERICAL COMPUTING WITH NUMPY</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INSTALL SOFTWARE AND IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\veronica\\appdata\\roaming\\python\\python312\\site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --user numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\veronica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATING VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights we will use to perform statisitcal analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2, w3 = 0.3, 0.2, 0.5\n",
    "weights_ls = [w1, w2, w3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several regions with their respective temperature, rainfall, and humidity data as lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanto = [73, 67, 43]\n",
    "johto = [91, 88, 64]\n",
    "hoenn = [87, 134, 58]\n",
    "sinnoh = [102, 43, 37]\n",
    "unova = [69, 96, 70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function crop_yield calculates the yield of somg crops given the climate data and respective weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_yield(region, weights):\n",
    "    result = 0\n",
    "    for x, w in zip(region, weights):\n",
    "        result += x * w\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore our data using the function we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.8"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_yield(kanto, weights_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.9"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_yield(johto, weights_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.9"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_yield(unova, weights_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CONVERTING PYTHON LISTS TO NUMPY ARRAYS\n",
    "crop_yield essentially performs a \"dot product\" calculation on two vectors.\n",
    "\n",
    "NumPy has a built in function that calculates dot products, but in order to use it, we must convert our lists to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73, 67, 43])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kanto = np.array([73, 67, 43])\n",
    "kanto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3, 0.2, 0.5])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.array([w1, w2, w3])\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further exploration shows that numpy arrays have their own data type classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(kanto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.8"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(kanto, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _ArrayFunctionDispatcher in module numpy:\n",
      "\n",
      "dot(...)\n",
      "    dot(a, b, out=None)\n",
      "\n",
      "    Dot product of two arrays. Specifically,\n",
      "\n",
      "    - If both `a` and `b` are 1-D arrays, it is inner product of vectors\n",
      "      (without complex conjugation).\n",
      "\n",
      "    - If both `a` and `b` are 2-D arrays, it is matrix multiplication,\n",
      "      but using :func:`matmul` or ``a @ b`` is preferred.\n",
      "\n",
      "    - If either `a` or `b` is 0-D (scalar), it is equivalent to\n",
      "      :func:`multiply` and using ``numpy.multiply(a, b)`` or ``a * b`` is\n",
      "      preferred.\n",
      "\n",
      "    - If `a` is an N-D array and `b` is a 1-D array, it is a sum product over\n",
      "      the last axis of `a` and `b`.\n",
      "\n",
      "    - If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a\n",
      "      sum product over the last axis of `a` and the second-to-last axis of\n",
      "      `b`::\n",
      "\n",
      "        dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n",
      "\n",
      "    It uses an optimized BLAS library when possible (see `numpy.linalg`).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        First argument.\n",
      "    b : array_like\n",
      "        Second argument.\n",
      "    out : ndarray, optional\n",
      "        Output argument. This must have the exact kind that would be returned\n",
      "        if it was not used. In particular, it must have the right type, must be\n",
      "        C-contiguous, and its dtype must be the dtype that would be returned\n",
      "        for `dot(a,b)`. This is a performance feature. Therefore, if these\n",
      "        conditions are not met, an exception is raised, instead of attempting\n",
      "        to be flexible.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        Returns the dot product of `a` and `b`.  If `a` and `b` are both\n",
      "        scalars or both 1-D arrays then a scalar is returned; otherwise\n",
      "        an array is returned.\n",
      "        If `out` is given, then it is returned.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If the last dimension of `a` is not the same size as\n",
      "        the second-to-last dimension of `b`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    vdot : Complex-conjugating dot product.\n",
      "    tensordot : Sum products over arbitrary axes.\n",
      "    einsum : Einstein summation convention.\n",
      "    matmul : '@' operator as method with out parameter.\n",
      "    linalg.multi_dot : Chained dot product.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.dot(3, 4)\n",
      "    12\n",
      "\n",
      "    Neither argument is complex-conjugated:\n",
      "\n",
      "    >>> np.dot([2j, 3j], [2j, 3j])\n",
      "    (-13+0j)\n",
      "\n",
      "    For 2-D arrays it is the matrix product:\n",
      "\n",
      "    >>> a = [[1, 0], [0, 1]]\n",
      "    >>> b = [[4, 1], [2, 2]]\n",
      "    >>> np.dot(a, b)\n",
      "    array([[4, 1],\n",
      "           [2, 2]])\n",
      "\n",
      "    >>> a = np.arange(3*4*5*6).reshape((3,4,5,6))\n",
      "    >>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))\n",
      "    >>> np.dot(a, b)[2,3,2,1,2,2]\n",
      "    499128\n",
      "    >>> sum(a[2,3,2,:] * b[1,2,:,2])\n",
      "    499128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays have advantages over Python lists:\n",
    "1. Ease of Use: makes mathematical expressions more concise\n",
    "2. Performance: Numpy is written in C++ internally, which is faster than Python\n",
    "\n",
    "See this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python lists\n",
    "arr1 = list(range(1000000))\n",
    "arr2 = list(range(1000000, 2000000))\n",
    "\n",
    "# Numpy arrays\n",
    "arr1_np = np.array(arr1, dtype=np.int64)\n",
    "arr2_np = np.array(arr2, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 141 ms\n",
      "Wall time: 138 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "833332333333500000"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "result = 0\n",
    "for x1, x2 in zip(arr1, arr2):\n",
    "    result += x1 * x2\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "833332333333500000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "np.dot(arr1_np, arr2_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: NumPy automatically uses np.int32 dtype arrays. In order to use np.dot() correctly, we must use np.int64 dtype arrays. We can convert the data type using dtype=\n",
    "\n",
    "If we forget to convert the data type, np.dot() will produce a negative value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MULTIDIMENSIONAL NUMPY ARRAYS\n",
    "We can represent all of our climate data together in a 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data = np.array([\n",
    "    [73, 67, 43],\n",
    "    [91, 88, 64], \n",
    "    [87, 134, 58], \n",
    "    [102, 43, 37], \n",
    "    [69, 96, 70]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the dimension of our multidimensional arrays using .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we can also create a 3D array using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_3d = np.array([\n",
    "    [[91, 88, 64], \n",
    "    [87, 134, 58]], \n",
    "\n",
    "    [[91, 88, 64], \n",
    "    [87, 134, 58]],  \n",
    "\n",
    "    [[91, 88, 64], \n",
    "    [87, 134, 58]],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 91,  88,  64],\n",
       "        [ 87, 134,  58]],\n",
       "\n",
       "       [[ 91,  88,  64],\n",
       "        [ 87, 134,  58]],\n",
       "\n",
       "       [[ 91,  88,  64],\n",
       "        [ 87, 134,  58]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating the shape of this 3D array will show us a tuple which can be understood as \"3 tables of 2 rows and 3 columns\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 3)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data_3d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of efficiency and performance, all elements in a numpy array will have the same data type. We can investigate this using .dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data_3d.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we create a numpy array with even 1 element that has a mismatching data type, all of the other elements in the array will be converted to match that data type. \n",
    "\n",
    "In the below example, we can see that all of the values in this array are integers except the element at (3, 1, 1), which is a float. When we investigate the data type for this array, it will be classified as float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_3d_demo = np.array([\n",
    "    [[91, 88, 64], \n",
    "    [87, 134, 58]], \n",
    "\n",
    "    [[91, 88, 64], \n",
    "    [87, 134, 58]],  \n",
    "\n",
    "    [[91.0, 88, 64], \n",
    "    [87, 134, 58]],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data_3d_demo.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using multidimensional arrays will allow us to calculate crop yields in all the regions at once. \n",
    "\n",
    "We can calculate the dot product of our 2D array and our weights using .matmul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56.8, 76.9, 81.9, 57.7, 74.9])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(climate_data, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to perform this calculation is using the @ operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56.8, 76.9, 81.9, 57.7, 74.9])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data @ weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WORKING WITH CSV DATA FILES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read CSV files into numpy arrays using the \"genfromtxt\" function.\n",
    "\n",
    "But first, we retrieve our CSV file from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('climate.txt', <http.client.HTTPMessage at 0x1e2d1e8d2b0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    'https://gist.github.com/BirajCoder/a4ffcb76fd6fb221d76ac2ee2b8584e9/raw/4054f90adfd361b7aa4255e99c2e874664094cea/climate.csv', \n",
    "    'climate.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25., 76., 99.],\n",
       "       [39., 65., 70.],\n",
       "       [59., 45., 77.],\n",
       "       ...,\n",
       "       [99., 62., 58.],\n",
       "       [70., 71., 91.],\n",
       "       [92., 39., 76.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_climate_data = np.genfromtxt('climate.txt', delimiter= ',', skip_header=1)\n",
    "\n",
    "extended_climate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_climate_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the dot product for our entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72.2, 59.7, 65.2, ..., 71.1, 80.7, 73.4])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_weighted_yield = extended_climate_data @ weights\n",
    "\n",
    "extended_weighted_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_weighted_yield.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add our results to our original matrix using np.concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = np.concatenate((extended_climate_data, extended_weighted_yield.reshape(10000, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we had to use np.reshape() to format the dimensions of our yields array and to then be able to use np.concatenate() properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _ArrayFunctionDispatcher in module numpy:\n",
      "\n",
      "reshape(a, newshape, order='C')\n",
      "    Gives a new shape to an array without changing its data.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array to be reshaped.\n",
      "    newshape : int or tuple of ints\n",
      "        The new shape should be compatible with the original shape. If\n",
      "        an integer, then the result will be a 1-D array of that length.\n",
      "        One shape dimension can be -1. In this case, the value is\n",
      "        inferred from the length of the array and remaining dimensions.\n",
      "    order : {'C', 'F', 'A'}, optional\n",
      "        Read the elements of `a` using this index order, and place the\n",
      "        elements into the reshaped array using this index order.  'C'\n",
      "        means to read / write the elements using C-like index order,\n",
      "        with the last axis index changing fastest, back to the first\n",
      "        axis index changing slowest. 'F' means to read / write the\n",
      "        elements using Fortran-like index order, with the first index\n",
      "        changing fastest, and the last index changing slowest. Note that\n",
      "        the 'C' and 'F' options take no account of the memory layout of\n",
      "        the underlying array, and only refer to the order of indexing.\n",
      "        'A' means to read / write the elements in Fortran-like index\n",
      "        order if `a` is Fortran *contiguous* in memory, C-like order\n",
      "        otherwise.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    reshaped_array : ndarray\n",
      "        This will be a new view object if possible; otherwise, it will\n",
      "        be a copy.  Note there is no guarantee of the *memory layout* (C- or\n",
      "        Fortran- contiguous) of the returned array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.reshape : Equivalent method.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    It is not always possible to change the shape of an array without copying\n",
      "    the data.\n",
      "\n",
      "    The `order` keyword gives the index ordering both for *fetching* the values\n",
      "    from `a`, and then *placing* the values into the output array.\n",
      "    For example, let's say you have an array:\n",
      "\n",
      "    >>> a = np.arange(6).reshape((3, 2))\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5]])\n",
      "\n",
      "    You can think of reshaping as first raveling the array (using the given\n",
      "    index order), then inserting the elements from the raveled array into the\n",
      "    new array using the same kind of index ordering as was used for the\n",
      "    raveling.\n",
      "\n",
      "    >>> np.reshape(a, (2, 3)) # C-like index ordering\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.reshape(a, (2, 3), order='F') # Fortran-like index ordering\n",
      "    array([[0, 4, 3],\n",
      "           [2, 1, 5]])\n",
      "    >>> np.reshape(np.ravel(a, order='F'), (2, 3), order='F')\n",
      "    array([[0, 4, 3],\n",
      "           [2, 1, 5]])\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1,2,3], [4,5,6]])\n",
      "    >>> np.reshape(a, 6)\n",
      "    array([1, 2, 3, 4, 5, 6])\n",
      "    >>> np.reshape(a, 6, order='F')\n",
      "    array([1, 4, 2, 5, 3, 6])\n",
      "\n",
      "    >>> np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also notice that axis is set to 1. This attribute ensures that we are working along the y axis of our matrix (columns). If we set our axis to 0, this would ensure that we're working along the x axis (rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _ArrayFunctionDispatcher in module numpy:\n",
      "\n",
      "concatenate(...)\n",
      "    concatenate((a1, a2, ...), axis=0, out=None, dtype=None, casting=\"same_kind\")\n",
      "\n",
      "    Join a sequence of arrays along an existing axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2, ... : sequence of array_like\n",
      "        The arrays must have the same shape, except in the dimension\n",
      "        corresponding to `axis` (the first, by default).\n",
      "    axis : int, optional\n",
      "        The axis along which the arrays will be joined.  If axis is None,\n",
      "        arrays are flattened before use.  Default is 0.\n",
      "    out : ndarray, optional\n",
      "        If provided, the destination to place the result. The shape must be\n",
      "        correct, matching that of what concatenate would have returned if no\n",
      "        out argument were specified.\n",
      "    dtype : str or dtype\n",
      "        If provided, the destination array will have this dtype. Cannot be\n",
      "        provided together with `out`.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    res : ndarray\n",
      "        The concatenated array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ma.concatenate : Concatenate function that preserves input masks.\n",
      "    array_split : Split an array into multiple sub-arrays of equal or\n",
      "                  near-equal size.\n",
      "    split : Split array into a list of multiple sub-arrays of equal size.\n",
      "    hsplit : Split array into multiple sub-arrays horizontally (column wise).\n",
      "    vsplit : Split array into multiple sub-arrays vertically (row wise).\n",
      "    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n",
      "    stack : Stack a sequence of arrays along a new axis.\n",
      "    block : Assemble arrays from blocks.\n",
      "    hstack : Stack arrays in sequence horizontally (column wise).\n",
      "    vstack : Stack arrays in sequence vertically (row wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third dimension).\n",
      "    column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When one or more of the arrays to be concatenated is a MaskedArray,\n",
      "    this function will return a MaskedArray object instead of an ndarray,\n",
      "    but the input masks are *not* preserved. In cases where a MaskedArray\n",
      "    is expected as input, use the ma.concatenate function from the masked\n",
      "    array module instead.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> b = np.array([[5, 6]])\n",
      "    >>> np.concatenate((a, b), axis=0)\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]])\n",
      "    >>> np.concatenate((a, b.T), axis=1)\n",
      "    array([[1, 2, 5],\n",
      "           [3, 4, 6]])\n",
      "    >>> np.concatenate((a, b), axis=None)\n",
      "    array([1, 2, 3, 4, 5, 6])\n",
      "\n",
      "    This function will not preserve masking of MaskedArray inputs.\n",
      "\n",
      "    >>> a = np.ma.arange(3)\n",
      "    >>> a[1] = np.ma.masked\n",
      "    >>> b = np.arange(2, 5)\n",
      "    >>> a\n",
      "    masked_array(data=[0, --, 2],\n",
      "                 mask=[False,  True, False],\n",
      "           fill_value=999999)\n",
      "    >>> b\n",
      "    array([2, 3, 4])\n",
      "    >>> np.concatenate([a, b])\n",
      "    masked_array(data=[0, 1, 2, 2, 3, 4],\n",
      "                 mask=False,\n",
      "           fill_value=999999)\n",
      "    >>> np.ma.concatenate([a, b])\n",
      "    masked_array(data=[0, --, 2, 2, 3, 4],\n",
      "                 mask=[False,  True, False, False, False, False],\n",
      "           fill_value=999999)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write the results to a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    'climate_results.txt',\n",
    "    final_results,\n",
    "    fmt='%.2f',\n",
    "    header='temperature, rainfall, humidity, yields',\n",
    "    comments=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _ArrayFunctionDispatcher in module numpy:\n",
      "\n",
      "savetxt(fname, X, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)\n",
      "    Save an array to a text file.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    fname : filename or file handle\n",
      "        If the filename ends in ``.gz``, the file is automatically saved in\n",
      "        compressed gzip format.  `loadtxt` understands gzipped files\n",
      "        transparently.\n",
      "    X : 1D or 2D array_like\n",
      "        Data to be saved to a text file.\n",
      "    fmt : str or sequence of strs, optional\n",
      "        A single format (%10.5f), a sequence of formats, or a\n",
      "        multi-format string, e.g. 'Iteration %d -- %10.5f', in which\n",
      "        case `delimiter` is ignored. For complex `X`, the legal options\n",
      "        for `fmt` are:\n",
      "\n",
      "        * a single specifier, `fmt='%.4e'`, resulting in numbers formatted\n",
      "          like `' (%s+%sj)' % (fmt, fmt)`\n",
      "        * a full string specifying every real and imaginary part, e.g.\n",
      "          `' %.4e %+.4ej %.4e %+.4ej %.4e %+.4ej'` for 3 columns\n",
      "        * a list of specifiers, one per column - in this case, the real\n",
      "          and imaginary part must have separate specifiers,\n",
      "          e.g. `['%.3e + %.3ej', '(%.15e%+.15ej)']` for 2 columns\n",
      "    delimiter : str, optional\n",
      "        String or character separating columns.\n",
      "    newline : str, optional\n",
      "        String or character separating lines.\n",
      "\n",
      "        .. versionadded:: 1.5.0\n",
      "    header : str, optional\n",
      "        String that will be written at the beginning of the file.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "    footer : str, optional\n",
      "        String that will be written at the end of the file.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "    comments : str, optional\n",
      "        String that will be prepended to the ``header`` and ``footer`` strings,\n",
      "        to mark them as comments. Default: '# ',  as expected by e.g.\n",
      "        ``numpy.loadtxt``.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "    encoding : {None, str}, optional\n",
      "        Encoding used to encode the outputfile. Does not apply to output\n",
      "        streams. If the encoding is something other than 'bytes' or 'latin1'\n",
      "        you will not be able to load the file in NumPy versions < 1.14. Default\n",
      "        is 'latin1'.\n",
      "\n",
      "        .. versionadded:: 1.14.0\n",
      "\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    save : Save an array to a binary file in NumPy ``.npy`` format\n",
      "    savez : Save several arrays into an uncompressed ``.npz`` archive\n",
      "    savez_compressed : Save several arrays into a compressed ``.npz`` archive\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Further explanation of the `fmt` parameter\n",
      "    (``%[flag]width[.precision]specifier``):\n",
      "\n",
      "    flags:\n",
      "        ``-`` : left justify\n",
      "\n",
      "        ``+`` : Forces to precede result with + or -.\n",
      "\n",
      "        ``0`` : Left pad the number with zeros instead of space (see width).\n",
      "\n",
      "    width:\n",
      "        Minimum number of characters to be printed. The value is not truncated\n",
      "        if it has more characters.\n",
      "\n",
      "    precision:\n",
      "        - For integer specifiers (eg. ``d,i,o,x``), the minimum number of\n",
      "          digits.\n",
      "        - For ``e, E`` and ``f`` specifiers, the number of digits to print\n",
      "          after the decimal point.\n",
      "        - For ``g`` and ``G``, the maximum number of significant digits.\n",
      "        - For ``s``, the maximum number of characters.\n",
      "\n",
      "    specifiers:\n",
      "        ``c`` : character\n",
      "\n",
      "        ``d`` or ``i`` : signed decimal integer\n",
      "\n",
      "        ``e`` or ``E`` : scientific notation with ``e`` or ``E``.\n",
      "\n",
      "        ``f`` : decimal floating point\n",
      "\n",
      "        ``g,G`` : use the shorter of ``e,E`` or ``f``\n",
      "\n",
      "        ``o`` : signed octal\n",
      "\n",
      "        ``s`` : string of characters\n",
      "\n",
      "        ``u`` : unsigned decimal integer\n",
      "\n",
      "        ``x,X`` : unsigned hexadecimal integer\n",
      "\n",
      "    This explanation of ``fmt`` is not complete, for an exhaustive\n",
      "    specification see [1]_.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Format Specification Mini-Language\n",
      "           <https://docs.python.org/library/string.html#format-specification-mini-language>`_,\n",
      "           Python Documentation.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = y = z = np.arange(0.0,5.0,1.0)\n",
      "    >>> np.savetxt('test.out', x, delimiter=',')   # X is an array\n",
      "    >>> np.savetxt('test.out', (x,y,z))   # x,y,z equal sized 1D arrays\n",
      "    >>> np.savetxt('test.out', x, fmt='%1.4e')   # use exponential notation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.savetxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARITHMETIC/COMPARISON OPERATIONS AND BROADCASTING\n",
    "As long as 2 arrays have the same dimensions or we are dealing with arrays and scalars, we can perform arithmetic and comparison operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3 = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10 , 11, 12]\n",
    "])\n",
    "\n",
    "arr4 = np.array([\n",
    "    [1, 1, 1, 1],\n",
    "    [2, 2, 2, 2],\n",
    "    [3, 3, 3, 3]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  4,  5],\n",
       "       [ 7,  8,  9, 10],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3 + arr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [10, 12, 14, 16],\n",
       "       [27, 30, 33, 36]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3 * arr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  5,  6],\n",
       "       [ 7,  8,  9, 10],\n",
       "       [11, 12, 13, 14]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr4 >= arr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the total number of elements that share the same value\n",
    "(arr4 == arr3).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays support \"broadcasting\", which allows us to work with arrays of differing dimensions as long as they have compatible shapes. 2 arrays are compatible if they share the same number of elements along at least 1 axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr5 = np.array([\n",
    "    [1, 1, 1, 1]\n",
    "])\n",
    "\n",
    "arr6 = np.array([\n",
    "    [2],\n",
    "    [2],\n",
    "    [2]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2],\n",
       "       [3, 3, 3, 3],\n",
       "       [4, 4, 4, 4]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr4 + arr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 3, 3],\n",
       "       [4, 4, 4, 4],\n",
       "       [5, 5, 5, 5]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr4 + arr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr4 == arr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the total number of elements that share the same value\n",
    "(arr4 == arr5).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARRAY INDEXING AND SLICING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a single elements (remember that indexing starts at 0)\n",
    "climate_data_3d_demo[1, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[91., 88.]],\n",
       "\n",
       "       [[91., 88.]]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subarray using ranges (remember that index ranges are exclusive)\n",
    "climate_data_3d_demo[1: , 0:1, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 2)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data_3d_demo[1: , 0:1, :2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58., 58.])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mixing indices and ranges\n",
    "climate_data_3d_demo[1: , 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 87., 134.,  58.],\n",
       "       [ 87., 134.,  58.],\n",
       "       [ 87., 134.,  58.]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using less than 3 indexing values\n",
    "climate_data_3d_demo[0: , 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OTHER NUMPY ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36628836, 0.94173094, 0.65658286, 0.25311551, 0.32613337])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A vector/array of random floats between 0 and 1\n",
    "np.random.rand(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A matrix of 0s\n",
    "np.zeros([3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.]]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A matrix of 1s\n",
    "np.ones((2, 2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: You can use brackets/tuples or parentheses/indices with these methods and still get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43126197,  0.3348622 ,  0.52706178],\n",
       "       [-1.10843974,  0.3010278 ,  1.76016534]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a matrix of samples from the standard normal distribution\n",
    "np.random.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42, 42, 42],\n",
       "       [42, 42, 42]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix of a fixed value\n",
    "np.full([2, 3], 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10, 13, 16],\n",
       "        [19, 22, 25],\n",
       "        [28, 31, 34]],\n",
       "\n",
       "       [[37, 40, 43],\n",
       "        [46, 49, 52],\n",
       "        [55, 58, 61]],\n",
       "\n",
       "       [[64, 67, 70],\n",
       "        [73, 76, 79],\n",
       "        [82, 85, 88]]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An array of a range with a start, end, and step and a specified dimension\n",
    "np.arange(10, 90, 3).reshape(3, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24., 27.])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equally spaced numbers in a range\n",
    "np.linspace(3, 27, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INTERACTING WITH OS AND FILESYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Veronica\\\\Documents\\\\python\\\\data_analysis'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '100_numpy_exercises.ipynb',\n",
       " 'climate.txt',\n",
       " 'climate_results.txt',\n",
       " 'lesson3_numerical_computing.ipynb',\n",
       " 'lesson4_analyzing_data.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For relative path\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$Recycle.Bin',\n",
       " '$WinREAgent',\n",
       " 'Documents and Settings',\n",
       " 'DumpStack.log.tmp',\n",
       " 'hiberfil.sys',\n",
       " 'pagefile.sys',\n",
       " 'PerfLogs',\n",
       " 'Program Files',\n",
       " 'Program Files (x86)',\n",
       " 'ProgramData',\n",
       " 'Recovery',\n",
       " 'swapfile.sys',\n",
       " 'System Volume Information',\n",
       " 'Users',\n",
       " 'Windows']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For absolute path\n",
    "os.listdir('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FXSEXT.ecf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/Windows')\n",
    "os.listdir('/Windows/addins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '100_numpy_exercises.ipynb',\n",
       " 'climate.txt',\n",
       " 'climate_results.txt',\n",
       " 'lesson3_numerical_computing.ipynb',\n",
       " 'lesson4_analyzing_data.ipynb']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/Users/Veronica/Documents/python/data_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beginner_python',\n",
       " 'data_analysis',\n",
       " 'data_structures_algorithms',\n",
       " 'intermediate_python',\n",
       " 'object_oriented_programming',\n",
       " 'quiz']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/Users/Veronica/Documents/python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm directory was made and is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'data' in os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download files into data directory using urllib module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://gist.githubusercontent.com/aakashns/257f6e6c8719c17d0e498ea287d1a386/raw/7def9ef4234ddf0bc82f855ad67dac8b971852ef/loans1.txt'\n",
    "url2 = 'https://gist.githubusercontent.com/aakashns/257f6e6c8719c17d0e498ea287d1a386/raw/7def9ef4234ddf0bc82f855ad67dac8b971852ef/loans2.txt'\n",
    "url3 = 'https://gist.githubusercontent.com/aakashns/257f6e6c8719c17d0e498ea287d1a386/raw/7def9ef4234ddf0bc82f855ad67dac8b971852ef/loans3.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/loans3.txt', <http.client.HTTPMessage at 0x1856d4dd6d0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(url1, './data/loans1.txt')\n",
    "urllib.request.urlretrieve(url2, './data/loans2.txt')\n",
    "urllib.request.urlretrieve(url3, './data/loans3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loans1.txt', 'loans2.txt', 'loans3.txt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open('./data/loans1.txt', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_contents = file1.read()\n",
    "file1_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount,duration,rate,down_payment\n",
      "100000,36,0.08,20000\n",
      "200000,12,0.1,\n",
      "628400,120,0.12,100000\n",
      "4637400,240,0.06,\n",
      "42900,90,0.07,8900\n",
      "916000,16,0.13,\n",
      "45230,48,0.08,4300\n",
      "991360,99,0.08,\n",
      "423000,27,0.09,47200\n"
     ]
    }
   ],
   "source": [
    "print(file1_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dont forget to close files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, to ensure we never forget to close our files, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount,duration,rate,down_payment\n",
      "828400,120,0.11,100000\n",
      "4633400,240,0.06,\n",
      "42900,90,0.08,8900\n",
      "983000,16,0.14,\n",
      "15230,48,0.07,4300\n"
     ]
    }
   ],
   "source": [
    "with open('./data/loans2.txt', mode='r') as file2:\n",
    "    file2_contents = file2.read()\n",
    "    print(file2_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a file line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/loans3.txt', mode='r') as file3:\n",
    "    # Contents as a list with newline characters\n",
    "    file3_lines = file3.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount,duration,rate,down_payment\\n',\n",
       " '45230,48,0.07,4300\\n',\n",
       " '883000,16,0.14,\\n',\n",
       " '100000,12,0.1,\\n',\n",
       " '728400,120,0.12,100000\\n',\n",
       " '3637400,240,0.06,\\n',\n",
       " '82900,90,0.07,8900\\n',\n",
       " '316000,16,0.13,\\n',\n",
       " '15230,48,0.08,4300\\n',\n",
       " '991360,99,0.08,\\n',\n",
       " '323000,27,0.09,4720010000,36,0.08,20000\\n',\n",
       " '528400,120,0.11,100000\\n',\n",
       " '8633400,240,0.06,\\n',\n",
       " '12900,90,0.08,8900']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file3_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amount,duration,rate,down_payment'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To remove newline characters\n",
    "file3_lines[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing data from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to convert the string of file contents into data types to be able to perform operations on it. \n",
    "\n",
    "1. Read file line by line\n",
    "2. Parse the first line to get column names (header)\n",
    "3. Split each remaining line in the file and convert the values to floats\n",
    "4. Create a dictionary for each loan (rows) using the column names as keys\n",
    "5. Create a list of dictionaries to keep track of all loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create functions for this process since it is useful for all CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_header(header_line):\n",
    "    return header_line.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_3 = parse_header(file3_lines[0])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_values(data_line):\n",
    "    values = []\n",
    "    for item in data_line.strip().split(','):\n",
    "        values.append(float(item))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function will lead to ValueError in places where values are missing (empty strings cant be converted to floats). We can enhance this function to handle such edge cases like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_values(data_line):\n",
    "    values = []\n",
    "    for item in data_line.strip().split(','):\n",
    "        if item == '':\n",
    "            values.append(0.0)\n",
    "        else:\n",
    "            values.append(float(item))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that takes a list of values and a list of headers, then returns a dictionary containing the values categorized under their respective headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_dict(values, headers):\n",
    "    result = {}\n",
    "    for value, header in zip(values, headers):\n",
    "        result[header] = value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we investigate zip(), we can see that it pairs elements in seperate iterables as tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on zip object:\n",
      "\n",
      "class zip(object)\n",
      " |  zip(*iterables, strict=False) --> Yield tuples until an input is exhausted.\n",
      " |\n",
      " |     >>> list(zip('abcdefg', range(3), range(4)))\n",
      " |     [('a', 0, 0), ('b', 1, 1), ('c', 2, 2)]\n",
      " |\n",
      " |  The zip object yields n-length tuples, where n is the number of iterables\n",
      " |  passed as positional arguments to zip().  The i-th element in every tuple\n",
      " |  comes from the i-th iterable argument to zip().  This continues until the\n",
      " |  shortest argument is exhausted.\n",
      " |\n",
      " |  If strict is true and one of the arguments is exhausted before the others,\n",
      " |  raise a ValueError.\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |\n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |\n",
      " |  __next__(self, /)\n",
      " |      Implement next(self).\n",
      " |\n",
      " |  __reduce__(...)\n",
      " |      Return state information for pickling.\n",
      " |\n",
      " |  __setstate__(...)\n",
      " |      Set state information for unpickling.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |\n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(zip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test create_item_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount': 883000.0, 'duration': 16.0, 'rate': 0.14, 'down_payment': 0.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values2 = parse_values(file3_lines[2])\n",
    "create_item_dict(values2, column_names_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all functions together to create read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    result = []\n",
    "    # Open file in read mode\n",
    "    with open(path, mode='r') as file:\n",
    "        # Get list of lines\n",
    "        lines = file.readlines()\n",
    "        # Parse header\n",
    "        headers = parse_header(lines[0])\n",
    "        # Loop over remaining lines\n",
    "        for data_line in lines[1:]:\n",
    "            # Parse values\n",
    "            values = parse_values(data_line)\n",
    "            # Create dictionary using values and headers\n",
    "            item_dict = create_item_dict(values, headers)\n",
    "            # Add dictionary to result\n",
    "            result.append(item_dict)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'amount': 100000.0, 'duration': 36.0, 'rate': 0.08, 'down_payment': 20000.0},\n",
       " {'amount': 200000.0, 'duration': 12.0, 'rate': 0.1, 'down_payment': 0.0},\n",
       " {'amount': 628400.0,\n",
       "  'duration': 120.0,\n",
       "  'rate': 0.12,\n",
       "  'down_payment': 100000.0},\n",
       " {'amount': 4637400.0, 'duration': 240.0, 'rate': 0.06, 'down_payment': 0.0},\n",
       " {'amount': 42900.0, 'duration': 90.0, 'rate': 0.07, 'down_payment': 8900.0},\n",
       " {'amount': 916000.0, 'duration': 16.0, 'rate': 0.13, 'down_payment': 0.0},\n",
       " {'amount': 45230.0, 'duration': 48.0, 'rate': 0.08, 'down_payment': 4300.0},\n",
       " {'amount': 991360.0, 'duration': 99.0, 'rate': 0.08, 'down_payment': 0.0},\n",
       " {'amount': 423000.0, 'duration': 27.0, 'rate': 0.09, 'down_payment': 47200.0}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans1_data = read_csv('./data/loans1.txt')\n",
    "loans1_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this function from Lesson 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def loan_emi(amount, duration, rate, down_payment=0):\n",
    "    loan_amount = amount - down_payment\n",
    "    try:\n",
    "        emi = loan_amount * rate * ((1 + rate)**duration) / (((1 + rate)**duration) - 1)\n",
    "    except ZeroDivisionError:\n",
    "        emi = loan_amount / duration\n",
    "    emi = math.ceil(emi)\n",
    "    return emi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate EMIs for all loans in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans2_data = read_csv('./data/loans2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loan in loans2_data:\n",
    "    loan['emi'] = loan_emi(loan['amount'],\n",
    "                           loan['duration'],\n",
    "                           loan['rate']/12,\n",
    "                           loan['down_payment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can transform this process into a function so that it can be performed on all files and loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emis(loans):\n",
    "    for loan in loans:\n",
    "        loan['emi'] = loan_emi(\n",
    "            loan['amount'],\n",
    "            loan['duration'],\n",
    "            loan['rate']/12,\n",
    "            loan['down_payment']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_emis(loans2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/emis2.txt', mode='w') as file:\n",
    "    for loan in loans2_data:\n",
    "        file.write(f'{loan['amount']}, {loan['duration']}, {loan['rate']}, {loan['down_payment']}, {loan['emi']}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that file was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emis2.txt', 'loans1.txt', 'loans2.txt', 'loans3.txt']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828400.0, 120.0, 0.11, 100000.0, 10034\n",
      "4633400.0, 240.0, 0.06, 0.0, 33196\n",
      "42900.0, 90.0, 0.08, 8900.0, 504\n",
      "983000.0, 16.0, 0.14, 0.0, 67707\n",
      "15230.0, 48.0, 0.07, 4300.0, 262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./data/emis2.txt') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a generic function that takes a list of dictionaries and writes it to a file in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(items, path):\n",
    "    # Open file in write mode\n",
    "    with open(path, mode='w') as file:\n",
    "        # Return if there's nothing to write\n",
    "        if len(items) == 0:\n",
    "            return\n",
    "        \n",
    "        # Write headers in first line\n",
    "        headers = list(items[0].keys())\n",
    "        file.write(','.join(headers) + '\\n')\n",
    "\n",
    "        # Write one item per line\n",
    "        for item in items:\n",
    "            values = []\n",
    "            for header in headers:\n",
    "                values.append(str(item.get(header, '')))\n",
    "            file.write(','.join(values) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
